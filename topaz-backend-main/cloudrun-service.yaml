apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: topaz-backend
  annotations:
    run.googleapis.com/ingress: all
    run.googleapis.com/execution-environment: gen2
spec:
  template:
    metadata:
      annotations:
        # Use the latest revision
        run.googleapis.com/execution-environment: gen2
        # Allow up to 1000 concurrent requests per instance
        run.googleapis.com/cpu-throttling: "false"
        autoscaling.knative.dev/maxScale: "10"
        autoscaling.knative.dev/minScale: "0"
    spec:
      # Set timeout for long-running requests
      timeoutSeconds: 300
      containerConcurrency: 80
      containers:
      - name: topaz-backend
        image: gcr.io/PROJECT_ID/topaz-backend:latest
        ports:
        - name: http1
          containerPort: 8080
        env:
        # Environment variables will be set during deployment
        - name: ENV
          value: "production"
        - name: LOG_LEVEL
          value: "INFO"
        # Add your environment variables here
        # - name: OPENAI_API_KEY
        #   valueFrom:
        #     secretKeyRef:
        #       name: openai-secret
        #       key: api-key
        resources:
          limits:
            cpu: "2"
            memory: "2Gi"
          requests:
            cpu: "1"
            memory: "512Mi"
        # Liveness probe
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        # Readiness probe
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3