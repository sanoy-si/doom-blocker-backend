import os
import json
import time
import logging
import asyncio
import re
from typing import Dict, Optional, Any, Union, List

from datetime import datetime

from dotenv import load_dotenv
from fastapi import FastAPI, Depends, HTTPException, Request, Response, status, WebSocket, WebSocketDisconnect
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware

from pydantic import BaseModel, Field
# from starlette.middleware.sessions import SessionMiddleware
# from authlib.integrations.starlette_client import OAuth, OAuthError
from supabase import create_client, Client

# HTTP requests
import requests

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv('.env.local')

# Load prompts from JSON
logger.info("Loading prompts from JSON file...")
import os
prompts_file_path = os.path.join(os.path.dirname(__file__), 'prompts_simplified.json')
try:
    with open(prompts_file_path, 'r') as f:
        prompts_data = json.load(f)
    logger.info("Prompts loaded successfully")
except FileNotFoundError:
    logger.error(f"Prompts file not found at {prompts_file_path}")
    # Fallback to empty prompts
    prompts_data = {}
except Exception as e:
    logger.error(f"Error loading prompts: {e}")
    prompts_data = {}

# Rate limiting infrastructure
rate_limit_data = {
    'ip_counts': {},  # IP -> request count
    'last_reset': time.time()  # timestamp of last reset
}

# Global counter for blocked items
blocked_items_counter = {
    'count': 0,
    'last_updated': time.time()
}

# Simple in-memory cache for API responses
api_cache = {
    'responses': {},  # hash -> response
    'max_size': 100,  # Maximum number of cached responses
    'max_age': 300    # Cache expires after 5 minutes
}

def reset_rate_limit_if_needed():
    """Reset rate limit counters if an hour has passed"""
    current_time = time.time()
    if current_time - rate_limit_data['last_reset'] >= 3600:  # 3600 seconds = 1 hour
        rate_limit_data['ip_counts'].clear()
        rate_limit_data['last_reset'] = current_time
        #logger.info("üîÑ Rate limit counters reset after 1 hour")

def track_ip_request(ip_address: str):
    """Track a request from the given IP address"""
    reset_rate_limit_if_needed()

    ip_counts = rate_limit_data['ip_counts']
    if ip_address not in ip_counts:
        ip_counts[ip_address] = 0

    ip_counts[ip_address] += 1
    request_count = ip_counts[ip_address]

    #logger.info(f"üìä IP {ip_address} has made {request_count} requests this hour")
    return request_count

app = FastAPI(title="Doom Blocker Backend", version="1.0.0")

# Add startup event for debugging
@app.on_event("startup")
async def startup_event():
    logger.info("üöÄ Doom Blocker Backend starting up...")
    logger.info(f"üìÅ Current working directory: {os.getcwd()}")
    logger.info(f"üìÑ Prompts loaded: {len(prompts_data)} patterns")
    logger.info(f"üîë OpenAI configured: {OPENAI_HEADERS is not None}")
    logger.info(f"üóÑÔ∏è Supabase configured: {supabase is not None}")
    logger.info("‚úÖ Startup complete!")

# WebSocket connection manager
class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        logger.info(f"WebSocket client connected. Total connections: {len(self.active_connections)}")

    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
        logger.info(f"WebSocket client disconnected. Total connections: {len(self.active_connections)}")

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            try:
                await connection.send_text(message)
            except Exception as e:
                logger.error(f"Error broadcasting to connection: {e}")

    async def broadcast_counter_update(self, count: int):
        """Broadcast counter update to all connected WebSocket clients"""
        message = json.dumps({
            "type": "counter_update",
            "count": count,
            "timestamp": time.time()
        })
        await self.broadcast(message)
        logger.info(f"Broadcasted counter update: {count}")

manager = ConnectionManager()

def increment_blocked_counter(items_blocked: int):
    """Increment the global blocked items counter and broadcast update"""
    blocked_items_counter['count'] += items_blocked
    blocked_items_counter['last_updated'] = time.time()
    
    # Schedule broadcast if there are active connections
    if manager.active_connections:
        asyncio.create_task(manager.broadcast_counter_update(blocked_items_counter['count']))
    
    logger.info(f"Blocked items counter updated: {blocked_items_counter['count']} (+{items_blocked})")

def get_cache_key(grid_structure, url, whitelist, blacklist):
    """Generate a cache key for the request"""
    import hashlib
    # Create a hash of the request parameters
    key_data = {
        'url': url,
        'whitelist': sorted(whitelist) if whitelist else [],
        'blacklist': sorted(blacklist) if blacklist else [],
        'grid_ids': [grid.get('id') for grid in grid_structure.get('grids', [])],
        'total_children': sum(grid.get('totalChildren', 0) for grid in grid_structure.get('grids', []))
    }
    key_string = json.dumps(key_data, sort_keys=True)
    return hashlib.md5(key_string.encode()).hexdigest()

def get_cached_response(cache_key):
    """Get cached response if available and not expired"""
    current_time = time.time()
    
    if cache_key in api_cache['responses']:
        cached_data = api_cache['responses'][cache_key]
        if current_time - cached_data['timestamp'] < api_cache['max_age']:
            logger.info(f"üéØ Cache hit for key: {cache_key[:8]}...")
            return cached_data['response']
        else:
            # Remove expired cache entry
            del api_cache['responses'][cache_key]
    
    return None

def cache_response(cache_key, response):
    """Cache the response"""
    current_time = time.time()
    
    # Clean up old cache entries if we're at max size
    if len(api_cache['responses']) >= api_cache['max_size']:
        # Remove oldest entries
        oldest_keys = sorted(api_cache['responses'].keys(), 
                           key=lambda k: api_cache['responses'][k]['timestamp'])[:10]
        for key in oldest_keys:
            del api_cache['responses'][key]
    
    api_cache['responses'][cache_key] = {
        'response': response,
        'timestamp': current_time
    }
    logger.info(f"üíæ Cached response for key: {cache_key[:8]}...")

# Add session middleware
# app.add_middleware(
#     SessionMiddleware,
#     secret_key=os.getenv("AUTH0_SECRET", "your-secret-key"),
#     max_age=3600,  # 1 hour in seconds
# )

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# AUTH0_CLIENT_ID = os.getenv("AUTH0_CLIENT_ID")
# AUTH0_CLIENT_SECRET = os.getenv("AUTH0_SECRET")
# AUTH0_ISSUER_BASE_URL = os.getenv("AUTH0_ISSUER_BASE_URL", "")
# AUTH0_DOMAIN = AUTH0_ISSUER_BASE_URL.replace("https://", "") if AUTH0_ISSUER_BASE_URL.startswith("https://") else AUTH0_ISSUER_BASE_URL
# BASE_URL = os.getenv("AUTH0_BASE_URL", "http://localhost:3000")

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_ANON_KEY")

# Initialize Supabase client only if credentials are provided and valid
if SUPABASE_URL and SUPABASE_KEY and not SUPABASE_URL.startswith("https://dummy"):
    try:
        supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
        logger.info("Supabase client initialized successfully")
    except Exception as e:
        logger.warning(f"Failed to initialize Supabase client: {e}")
        supabase = None
else:
    logger.warning("Supabase disabled (dummy/missing credentials)")
    supabase = None

async def update_visitor_telemetry(visitor_id: str):
    """Update visitor telemetry in Supabase asynchronously - DISABLED for performance"""
    # DISABLED: Telemetry calls are causing 404 errors and slowing down the API
    # The telemetry table doesn't exist or isn't accessible, causing delays
    logger.debug("Telemetry update disabled for performance - skipping visitor tracking")
    return

# oauth = OAuth()
# oauth.register(
#     name="auth0",
#     client_id=AUTH0_CLIENT_ID,
#     client_secret=AUTH0_CLIENT_SECRET,
#     client_kwargs={"scope": "openid profile email"},
#     server_metadata_url=f"https://{AUTH0_DOMAIN}/.well-known/openid-configuration",
# )

logger.info("Initializing OpenAI API configuration...")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.warning("OPENAI_API_KEY not found - AI analysis will be disabled")
    OPENAI_HEADERS = None
else:
    OPENAI_URL = "https://api.openai.com/v1/chat/completions"
    OPENAI_HEADERS = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }
    logger.info("OpenAI client initialized successfully")

class GridAnalysisRequest(BaseModel):
    gridStructure: dict
    currentUrl: str
    whitelist: list[str] = []
    blacklist: list[str] = []
    visitorId: str

class AnalysisResult(BaseModel):
    """
    Complete analysis result containing removal instructions for interface cleanup.

    This is the final output that specifies exactly which UI elements should be hidden
    from the grid interface as a newline-separated list.
    """
    children_to_remove: str = Field(
        description="Newline-separated list of child element IDs that should be removed. Each ID must exactly match a child ID from the input data (e.g., 'g1c0\\ng1c5\\ng1c3\\ng2c9'). Return empty string if no children should be removed.",
        example="g1c0\ng1c5\ng1c3\ng2c9"
    )

# Pydantic models for user session and analytics endpoints
class UserSessionRequest(BaseModel):
    session_id: str
    device_info: dict
    created_at: str
    extension_version: str
    first_install: bool = False

class BlockedItemsRequest(BaseModel):
    session_id: str
    blocked_items: List[dict]

class UserMetricsRequest(BaseModel):
    session_id: str
    total_blocked: int = 0
    blocked_today: int = 0
    sites_visited: List[dict] = []
    profiles_used: List[dict] = []
    last_updated: str

# Pydantic models for other API endpoints
# class Username(BaseModel):
#     username: str

# class ScoreData(BaseModel):
#     username: str
#     score: int

# Helper functions
# def get_user_from_session(request: Request) -> Optional[Dict[str, Any]]:
#     """Extract user information from session."""
#     return request.session.get("user")

# def is_authenticated(request: Request) -> bool:
#     """Check if the user is authenticated."""
#     return "user" in request.session and request.session["user"] is not None

# async def require_auth(request: Request) -> Dict[str, Any]:
#     """Dependency to require authentication."""
#     user = get_user_from_session(request)
#     if not user:
#         raise HTTPException(status_code=401, detail="Not authenticated")
#     return user

def get_prompt_for_url(url: str, whitelist: list[str] = None, blacklist: list[str] = None) -> str:
    """Get the appropriate prompt based on URL regex matching"""
    # Detect YouTube search URL and extract search query
    youtube_search_match = re.match(r"https?://(www\.)?youtube\.com/results\?(.+)", url)
    search_query = None
    if youtube_search_match:
        # Extract the search_query parameter from the URL
        from urllib.parse import parse_qs, urlparse
        qs = parse_qs(urlparse(url).query)
        search_query = qs.get("search_query", [None])[0]

    for pattern, config in prompts_data.items():
        if re.match(pattern, url):
            prompt = config["prompt"]

            # Replace blacklist and whitelist tags
            if blacklist and len(blacklist) > 0:
                blacklist_items = "\n".join(["- %s" % item for item in blacklist])
                prompt = prompt.replace("<BLACKLIST>", "<BLACKLIST>\n%s" % blacklist_items)
            else:
                prompt = prompt.replace("<BLACKLIST>", "")

            if whitelist and len(whitelist) > 0:
                whitelist_items = "\n".join(["- %s" % item for item in whitelist])
                prompt = prompt.replace("<WHITELIST>", "<WHITELIST>\n%s" % whitelist_items)
            else:
                prompt = prompt.replace("<WHITELIST>", "")

            # If YouTube search, add the search query to the prompt
            if search_query:
                prompt += f"\n\nUSER_SEARCH_QUERY: {search_query}\nOnly keep videos and results relevant to this search query."



            return prompt

    # Default fallback (shouldn't happen with proper config)
    logger.warning("No matching pattern found for URL: %s" % url)
    base_prompt = list(prompts_data.values())[0]["prompt"]

    # Apply same replacement logic for fallback
    if blacklist and len(blacklist) > 0:
        blacklist_items = "\n".join(["- %s" % item for item in blacklist])
        base_prompt = base_prompt.replace("<BLACKLIST>", "<BLACKLIST>\n%s" % blacklist_items)
    else:
        base_prompt = base_prompt.replace("<BLACKLIST>", "")

    if whitelist and len(whitelist) > 0:
        whitelist_items = "\n".join(["- %s" % item for item in whitelist])
        base_prompt = base_prompt.replace("<WHITELIST>", "<WHITELIST>\n%s" % whitelist_items)
    else:
        base_prompt = base_prompt.replace("<WHITELIST>", "")

    # If YouTube search, add the search query to the fallback prompt
    if search_query:
        base_prompt += f"\n\nUSER_SEARCH_QUERY: {search_query}\nOnly keep videos and results relevant to this search query."



    return base_prompt

# WebSocket endpoint
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    
    # Send current counter value to newly connected client
    try:
        initial_message = json.dumps({
            "type": "counter_update",
            "count": blocked_items_counter['count'],
            "timestamp": time.time()
        })
        await manager.send_personal_message(initial_message, websocket)
    except Exception as e:
        logger.error(f"Error sending initial counter: {e}")
    
    try:
        while True:
            data = await websocket.receive_text()
            logger.info(f"Received WebSocket message: {data}")
            
            # Handle incoming messages (can be extended for different message types)
            try:
                message = json.loads(data)
                if message.get("type") == "get_counter":
                    counter_message = json.dumps({
                        "type": "counter_update",
                        "count": blocked_items_counter['count'],
                        "timestamp": time.time()
                    })
                    await manager.send_personal_message(counter_message, websocket)
            except json.JSONDecodeError:
                # Handle plain text messages
                await manager.send_personal_message(f"Echo: {data}", websocket)
            
    except WebSocketDisconnect:
        manager.disconnect(websocket)
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
        manager.disconnect(websocket)

# Root endpoint
@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "message": "Doom Blocker Backend API",
        "status": "running",
        "timestamp": time.time(),
        "endpoints": {
            "health": "/health",
            "docs": "/docs",
            "blocked_count": "/api/blocked-count",
            "ai_analysis": "/fetch_distracting_chunks"
        }
    }

# Health check endpoint
@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": time.time(),
        "openai_configured": OPENAI_HEADERS is not None
    }

# REST endpoint to get current counter (optional)
@app.get("/api/blocked-count")
async def get_blocked_count():
    """Get the current count of blocked items"""
    return {
        "count": blocked_items_counter['count'],
        "last_updated": blocked_items_counter['last_updated']
    }

@app.post("/api/report-blocked-items")
async def report_blocked_items(request: Request):
    """Report actually blocked items from the extension"""
    try:
        data = await request.json()
        count = data.get('count', 0)
        
        if count > 0:
            increment_blocked_counter(count)
            logger.info(f"üìä Extension reported {count} actually blocked items")
        
        return {"success": True, "count": count}
    except Exception as e:
        logger.error(f"‚ùå Error reporting blocked items: {e}")
        return {"success": False, "error": str(e)}

# Auth routes
# @app.get("/login")
# async def login(request: Request):
#     redirect_uri = f"{BASE_URL}/callback"
#     return await oauth.auth0.authorize_redirect(request, redirect_uri)

# @app.get("/callback")
# async def callback(request: Request):
#     try:
#         token = await oauth.auth0.authorize_access_token(request)
#         user = token.get("userinfo")
#         if user:
#             request.session["user"] = dict(user)
#             return RedirectResponse(url="/")
#         else:
#             return JSONResponse(
#                 status_code=400,
#                 content={"error": "Failed to get user info"}
#             )
#     except OAuthError as e:
#         return JSONResponse(
#             status_code=400,
#             content={"error": f"OAuth error: {str(e)}"}
#         )

# @app.get("/logout")
# async def logout(request: Request, response: Response):
#     request.session.pop("user", None)
#     response.delete_cookie("session")

#     # Auth0 logout URL for redirection
#     return_to = f"{BASE_URL}"
#     logout_url = f"{AUTH0_ISSUER_BASE_URL}/v2/logout?client_id={AUTH0_CLIENT_ID}&returnTo={return_to}"

#     # Return redirection to Auth0 logout
#     return RedirectResponse(url=logout_url)



# User Session and Analytics Endpoints

@app.post("/api/user-session")
async def create_user_session(session_request: UserSessionRequest, request: Request):
    """Create or update user session in Supabase"""
    try:
        if not supabase:
            logger.warning("Supabase not configured, session not saved")
            return {"success": True, "message": "Session tracking disabled"}

        # Prepare session data for Supabase
        session_data = {
            "session_id": session_request.session_id,
            "device_info": session_request.device_info,
            "created_at": session_request.created_at,
            "extension_version": session_request.extension_version,
            "first_install": session_request.first_install,
            "ip_address": request.client.host if request.client else "unknown",
            "last_active": datetime.now().isoformat()
        }

        # Upsert session data
        result = supabase.table("user_sessions").upsert(
            session_data,
            on_conflict="session_id"
        ).execute()

        logger.info(f"‚úÖ User session saved: {session_request.session_id}")

        return {
            "success": True,
            "message": "Session saved successfully",
            "session_id": session_request.session_id
        }

    except Exception as e:
        logger.error(f"‚ùå Error saving user session: {e}")
        return JSONResponse(
            status_code=500,
            content={"success": False, "error": str(e)}
        )

@app.post("/api/blocked-items")
async def save_blocked_items(blocked_request: BlockedItemsRequest, request: Request):
    """Save blocked items data to Supabase"""
    try:
        if not supabase:
            logger.warning("Supabase not configured, blocked items not saved")
            return {"success": True, "message": "Blocked items tracking disabled"}

        # Prepare blocked items data
        blocked_records = []
        for item in blocked_request.blocked_items:
            record = {
                "session_id": blocked_request.session_id,
                "timestamp": item.get("timestamp"),
                "count": item.get("count", 0),
                "url": item.get("url", ""),
                "hostname": item.get("hostname", ""),
                "blocked_items": item.get("items", []),
                "created_at": datetime.now().isoformat()
            }
            blocked_records.append(record)

        # Insert blocked items data
        if blocked_records:
            result = supabase.table("blocked_items").insert(blocked_records).execute()
            logger.info(f"‚úÖ Saved {len(blocked_records)} blocked items for session {blocked_request.session_id}")

        return {
            "success": True,
            "message": f"Saved {len(blocked_records)} blocked items",
            "count": len(blocked_records)
        }

    except Exception as e:
        logger.error(f"‚ùå Error saving blocked items: {e}")
        return JSONResponse(
            status_code=500,
            content={"success": False, "error": str(e)}
        )

@app.post("/api/user-metrics")
async def save_user_metrics(metrics_request: UserMetricsRequest, request: Request):
    """Save user metrics to Supabase"""
    try:
        if not supabase:
            logger.warning("Supabase not configured, metrics not saved")
            return {"success": True, "message": "Metrics tracking disabled"}

        # Prepare metrics data
        metrics_data = {
            "session_id": metrics_request.session_id,
            "total_blocked": metrics_request.total_blocked,
            "blocked_today": metrics_request.blocked_today,
            "sites_visited": metrics_request.sites_visited,
            "profiles_used": metrics_request.profiles_used,
            "last_updated": metrics_request.last_updated,
            "updated_at": datetime.now().isoformat()
        }

        # Upsert metrics data
        result = supabase.table("user_metrics").upsert(
            metrics_data,
            on_conflict="session_id"
        ).execute()

        logger.info(f"‚úÖ User metrics saved for session {metrics_request.session_id}")

        return {
            "success": True,
            "message": "Metrics saved successfully",
            "session_id": metrics_request.session_id
        }

    except Exception as e:
        logger.error(f"‚ùå Error saving user metrics: {e}")
        return JSONResponse(
            status_code=500,
            content={"success": False, "error": str(e)}
        )

@app.get("/api/analytics/{session_id}")
async def get_user_analytics(session_id: str):
    """Get analytics data for a specific user session"""
    try:
        if not supabase:
            return JSONResponse(
                status_code=503,
                content={"success": False, "error": "Analytics service unavailable"}
            )

        # Get user metrics
        metrics_result = supabase.table("user_metrics").select("*").eq("session_id", session_id).execute()

        # Get blocked items data
        blocked_result = supabase.table("blocked_items").select("*").eq("session_id", session_id).execute()

        # Get session info
        session_result = supabase.table("user_sessions").select("*").eq("session_id", session_id).execute()

        analytics_data = {
            "session_id": session_id,
            "metrics": metrics_result.data[0] if metrics_result.data else None,
            "blocked_items": blocked_result.data,
            "session_info": session_result.data[0] if session_result.data else None,
            "summary": {
                "total_records": len(blocked_result.data),
                "total_blocked": sum(item.get("count", 0) for item in blocked_result.data),
                "unique_sites": len(set(item.get("hostname", "") for item in blocked_result.data if item.get("hostname")))
            }
        }

        return {
            "success": True,
            "data": analytics_data
        }

    except Exception as e:
        logger.error(f"‚ùå Error fetching analytics: {e}")
        return JSONResponse(
            status_code=500,
            content={"success": False, "error": str(e)}
        )

@app.get("/analytics")
async def analytics_frontend(request: Request):
    """Serve the analytics frontend page"""
    from fastapi.responses import HTMLResponse

    # Get session ID from query parameter
    session_id = request.query_params.get("session")

    html_content = f"""
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Doom Blocker Analytics</title>
        <style>
            * {{
                margin: 0;
                padding: 0;
                box-sizing: border-box;
            }}

            body {{
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
                background: #1a1a1a;
                color: #fff;
                line-height: 1.6;
            }}

            .container {{
                max-width: 1200px;
                margin: 0 auto;
                padding: 20px;
            }}

            .header {{
                text-align: center;
                margin-bottom: 40px;
                padding: 20px 0;
                border-bottom: 1px solid #333;
            }}

            .header h1 {{
                color: #ff9823;
                font-size: 2.5rem;
                margin-bottom: 10px;
            }}

            .header p {{
                color: #ccc;
                font-size: 1.1rem;
            }}

            .stats-grid {{
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
                gap: 20px;
                margin-bottom: 40px;
            }}

            .stat-card {{
                background: #252525;
                border-radius: 12px;
                padding: 24px;
                border: 1px solid #333;
                transition: transform 0.2s ease;
            }}

            .stat-card:hover {{
                transform: translateY(-2px);
                border-color: #ff9823;
            }}

            .stat-number {{
                font-size: 2.5rem;
                font-weight: bold;
                color: #ff9823;
                margin-bottom: 8px;
            }}

            .stat-label {{
                color: #ccc;
                font-size: 1rem;
                text-transform: uppercase;
                letter-spacing: 0.5px;
            }}

            .loading {{
                text-align: center;
                padding: 60px 20px;
                color: #ccc;
                font-size: 1.2rem;
            }}

            .error {{
                text-align: center;
                padding: 60px 20px;
                color: #ff6b6b;
                font-size: 1.2rem;
            }}

            .activity-section {{
                background: #252525;
                border-radius: 12px;
                padding: 24px;
                border: 1px solid #333;
                margin-bottom: 20px;
            }}

            .section-title {{
                color: #ff9823;
                font-size: 1.5rem;
                margin-bottom: 20px;
                padding-bottom: 10px;
                border-bottom: 1px solid #333;
            }}

            .activity-item {{
                padding: 12px 0;
                border-bottom: 1px solid #333;
                display: flex;
                justify-content: space-between;
                align-items: center;
            }}

            .activity-item:last-child {{
                border-bottom: none;
            }}

            .activity-text {{
                color: #ccc;
                flex: 1;
            }}

            .activity-count {{
                color: #ff9823;
                font-weight: bold;
                margin-left: 10px;
            }}

            .session-info {{
                background: #252525;
                border-radius: 12px;
                padding: 24px;
                border: 1px solid #333;
                margin-bottom: 20px;
            }}

            .info-row {{
                display: flex;
                justify-content: space-between;
                padding: 8px 0;
                border-bottom: 1px solid #333;
            }}

            .info-row:last-child {{
                border-bottom: none;
            }}

            .info-label {{
                color: #999;
            }}

            .info-value {{
                color: #fff;
                font-weight: 500;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>üìä Doom Blocker Analytics</h1>
                <p>Your content filtering insights and statistics</p>
            </div>

            <div id="content">
                <div class="loading">
                    Loading your analytics data...
                </div>
            </div>
        </div>

        <script>
            const sessionId = "{session_id or ''}";

            async function loadAnalytics() {{
                try {{
                    if (!sessionId) {{
                        document.getElementById('content').innerHTML = `
                            <div class="error">
                                No session ID provided. Please access analytics through the extension.
                            </div>
                        `;
                        return;
                    }}

                    const response = await fetch(`/api/analytics/${{sessionId}}`);
                    const result = await response.json();

                    if (!result.success) {{
                        throw new Error(result.error || 'Failed to load analytics');
                    }}

                    const data = result.data;
                    renderAnalytics(data);

                }} catch (error) {{
                    console.error('Error loading analytics:', error);
                    document.getElementById('content').innerHTML = `
                        <div class="error">
                            Failed to load analytics: ${{error.message}}
                        </div>
                    `;
                }}
            }}

            function renderAnalytics(data) {{
                const metrics = data.metrics || {{}};
                const summary = data.summary || {{}};
                const sessionInfo = data.session_info || {{}};
                const blockedItems = data.blocked_items || [];

                // Group blocked items by hostname
                const siteStats = {{}};
                blockedItems.forEach(item => {{
                    const hostname = item.hostname || 'Unknown';
                    if (!siteStats[hostname]) {{
                        siteStats[hostname] = 0;
                    }}
                    siteStats[hostname] += item.count || 0;
                }});

                const sortedSites = Object.entries(siteStats)
                    .sort(([,a], [,b]) => b - a)
                    .slice(0, 10);

                document.getElementById('content').innerHTML = `
                    <div class="stats-grid">
                        <div class="stat-card">
                            <div class="stat-number">${{metrics.total_blocked || 0}}</div>
                            <div class="stat-label">Total Blocked</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-number">${{metrics.blocked_today || 0}}</div>
                            <div class="stat-label">Blocked Today</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-number">${{summary.unique_sites || 0}}</div>
                            <div class="stat-label">Sites Protected</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-number">${{blockedItems.length}}</div>
                            <div class="stat-label">Filter Events</div>
                        </div>
                    </div>

                    <div class="session-info">
                        <h2 class="section-title">Session Information</h2>
                        <div class="info-row">
                            <span class="info-label">Session ID:</span>
                            <span class="info-value">${{data.session_id.substring(0, 8)}}...</span>
                        </div>
                        <div class="info-row">
                            <span class="info-label">Extension Version:</span>
                            <span class="info-value">${{sessionInfo.extension_version || 'Unknown'}}</span>
                        </div>
                        <div class="info-row">
                            <span class="info-label">Created:</span>
                            <span class="info-value">${{new Date(sessionInfo.created_at || Date.now()).toLocaleDateString()}}</span>
                        </div>
                        <div class="info-row">
                            <span class="info-label">First Install:</span>
                            <span class="info-value">${{sessionInfo.first_install ? 'Yes' : 'No'}}</span>
                        </div>
                    </div>

                    <div class="activity-section">
                        <h2 class="section-title">Top Sites by Blocked Content</h2>
                        ${{sortedSites.length > 0 ? sortedSites.map(([site, count]) => `
                            <div class="activity-item">
                                <span class="activity-text">${{site}}</span>
                                <span class="activity-count">${{count}} items</span>
                            </div>
                        `).join('') : '<div class="activity-text">No data available</div>'}}
                    </div>

                    <div class="activity-section">
                        <h2 class="section-title">All Blocked Items (${{blockedItems.length}} total)</h2>
                        <div style="max-height: 400px; overflow-y: auto; border: 1px solid #333; border-radius: 8px; padding: 10px;">
                        ${{blockedItems.map(item => `
                            <div class="activity-item">
                                <div class="activity-text">
                                    <div style="font-weight: 500; margin-bottom: 4px;">
                                        ${{new Date(item.timestamp).toLocaleString()}} - ${{item.hostname || 'Unknown'}}
                                    </div>
                                    ${{item.blocked_items && item.blocked_items.length > 0 ? `
                                        <div style="font-size: 0.9em; color: #999; margin-left: 20px;">
                                            ${{'‚Ä¢ ' + item.blocked_items.slice(0, 3).map(blockedItem =>
                                                typeof blockedItem === 'string' ? blockedItem :
                                                (blockedItem.text || blockedItem.title || 'Blocked content')
                                            ).join('<br>‚Ä¢ ')}}
                                            ${{item.blocked_items.length > 3 ? `<br>‚Ä¢ ...and ${{item.blocked_items.length - 3}} more` : ''}}
                                        </div>
                                    ` : ''}}
                                </div>
                                <span class="activity-count">${{item.count}} blocked</span>
                            </div>
                        `).join('')}}
                        </div>
                    </div>
                `;
            }}

            // Load analytics on page load
            loadAnalytics();
        </script>
    </body>
    </html>
    """

    return HTMLResponse(content=html_content)

@app.post("/fetch_distracting_chunks")
async def fetch_distracting_chunks(analysis_request: GridAnalysisRequest, request: Request): # user: Dict = Depends(require_auth)):
    # Configuration - process entire grid structure in one call

    # Track the request by IP address
    client_ip = request.client.host if request.client else "unknown"
    request_count = track_ip_request(client_ip)

    # DISABLED: Update visitor telemetry in Supabase (fire and forget)
    # asyncio.create_task(update_visitor_telemetry(analysis_request.visitorId))

    # Check rate limit
    if request_count > 3000:

        raise HTTPException(
            status_code=429,
            detail="RATE_LIMIT_EXCEEDED"
        )

    start_time = time.time()

    # Log grid structure details
    grid_structure = analysis_request.gridStructure
    total_grids = grid_structure.get('totalGrids', 0)
    total_children = sum(grid.get('totalChildren', 0) for grid in grid_structure.get('grids', []))

    # Check cache first
    cache_key = get_cache_key(grid_structure, analysis_request.currentUrl, 
                             analysis_request.whitelist, analysis_request.blacklist)
    cached_response = get_cached_response(cache_key)
    
    if cached_response is not None:
        logger.info(f"‚ö° Returning cached response - Total time: {time.time() - start_time:.3f}s")
        return cached_response

    try:
        prompt_start = time.time()
        base_system_instruction = get_prompt_for_url(analysis_request.currentUrl, analysis_request.whitelist, analysis_request.blacklist)
        logger.info(f"üìã Base system instruction loaded ({time.time() - prompt_start:.3f}s)")

        # Check if OpenAI API is configured
        if not OPENAI_HEADERS:
            raise HTTPException(
                status_code=503,
                detail="AI_SERVICE_UNAVAILABLE: OpenAI API not configured"
            )

        # Process entire grid structure in one API call
        api_start = time.time()

        # Clean grid data before sending to LLM
        cleaned_grid = clean_grid_structure_for_llm(grid_structure)

        # Build strong system prompt with explicit schema and valid IDs to avoid hallucinations
        def get_valid_child_ids(cleaned):
            ids = []
            for grid in cleaned.get('grids', []):
                for child in grid.get('children', []):
                    cid = child.get('id')
                    if cid:
                        ids.append(cid)
            return ids

        def build_system_prompt(base_prompt: str, cleaned: dict) -> str:
            valid_ids = get_valid_child_ids(cleaned)
            ids_block = "\n".join(valid_ids)
            rules = (
                "\n\nSTRICT OUTPUT RULES:\n"
                "- Output ONLY a newline-separated list of child IDs to hide (e.g., g1c0, g1c5).\n"
                "- Do NOT include any explanations, JSON, code fences, or extra text.\n"
                "- If nothing should be hidden, return an empty string.\n"
                "- You MUST only return IDs from the VALID_CHILD_IDS list below. Never invent IDs.\n"
                "- Prefer to hide content matching blacklist terms and unrelated to whitelist intent.\n"
                "\nVALID_CHILD_IDS:\n" + ids_block + "\n"
            )
            return f"{base_prompt}{rules}"

        system_instruction = build_system_prompt(base_system_instruction, cleaned_grid)
        content = json.dumps(cleaned_grid, indent=2)
        
        # DEBUG: Log what we're sending to the AI
        logger.info(f"üîç DEBUG: Sending to AI - URL: {analysis_request.currentUrl}")
        logger.info(f"üîç DEBUG: Whitelist: {analysis_request.whitelist}")
        logger.info(f"üîç DEBUG: Blacklist: {analysis_request.blacklist}")
        logger.info(f"üîç DEBUG: Grid structure has {len(cleaned_grid.get('grids', []))} grids")
        logger.info(f"üîç DEBUG: Total children: {sum(grid.get('totalChildren', 0) for grid in cleaned_grid.get('grids', []))}")
        logger.info(f"üîç DEBUG: System instruction length: {len(system_instruction)} chars")


        payload = {
            "model": "gpt-4o-mini",  # Use a valid OpenAI model
            "messages": [
                {
                    "role": "system",
                    "content": system_instruction
                },
                {
                    "role": "user",
                    "content": content
                }
            ],
            "max_tokens": 256,  # Much smaller for faster response
            "temperature": 0.6  # Deterministic for consistent results
        }

        response = requests.post(OPENAI_URL, headers=OPENAI_HEADERS, json=payload, timeout=30)

        if response.status_code != 200:

            raise HTTPException(status_code=500, detail=f"OpenAI API error: {response.status_code} - {response.text}")

        api_result = response.json()
        response_content = api_result['choices'][0]['message']['content'].strip()

        api_duration = time.time() - api_start
        logger.info(f"‚úÖ OpenAI API call completed ({api_duration:.3f}s)")
        
        # DEBUG: Log what the AI returned
        logger.info(f"üîç DEBUG: AI response length: {len(response_content)} chars")
        logger.info(f"üîç DEBUG: AI response preview: {response_content[:200]}...")

        # Parse and sanitize the result
        parse_start = time.time()

        def sanitize_llm_response(text: str, cleaned: dict) -> str:
            """Extract only valid child IDs present in the cleaned grid from arbitrary model text."""
            try:
                # Collect valid IDs set
                valid = set()
                for grid in cleaned.get('grids', []):
                    for child in grid.get('children', []):
                        cid = child.get('id')
                        if cid:
                            valid.add(cid)
                # Regex to find tokens like g12c3 etc.
                ids = re.findall(r"g\d+c\d+", text or "")
                # Filter to only valid ids and deduplicate preserving order
                seen = set()
                filtered = []
                for cid in ids:
                    if cid in valid and cid not in seen:
                        filtered.append(cid)
                        seen.add(cid)
                return "\n".join(filtered)
            except Exception:
                return ""

        # Sanitize first, then convert
        sanitized = sanitize_llm_response(response_content, cleaned_grid)
        if sanitized and sanitized.strip():
            result = convert_newline_format_to_json(sanitized)
            total_children_to_remove = len([child for child in sanitized.split('\n') if child.strip()])
        else:
            # FALLBACK: If AI returns empty, try simple keyword matching
            logger.warning("ü§ñ AI returned empty response, trying fallback keyword matching")
            result = fallback_keyword_matching(cleaned_grid, analysis_request.blacklist)
            total_children_to_remove = len(result)
            logger.info(f"üîÑ Fallback found {total_children_to_remove} items to remove")

        parse_duration = time.time() - parse_start
        logger.info(f"üéØ Found {total_children_to_remove} children to remove ({parse_duration:.3f}s)")

        total_duration = time.time() - start_time
        logger.info(f"‚úÖ Request completed successfully - Total time: {total_duration:.3f}s")
        logger.info(f"‚è±Ô∏è  Breakdown: API={api_duration:.3f}s, Other={total_duration-api_duration:.3f}s")

        # REMOVED: Don't count as blocked until extension confirms they were actually hidden
        # increment_blocked_counter(total_children_to_remove)

        # Cache the response for future requests
        cache_response(cache_key, result)

        return result

    except Exception as e:
        error_duration = time.time() - start_time
        logger.error("Request failed after %.3fs: %s" % (error_duration, str(e)))

        raise HTTPException(status_code=500, detail=str(e))


def split_grid_into_chunks(grid_structure, chunk_size):
    """
    Split grid structure into chunks for batched API requests
    Splits by total children count across all grids
    """
    # Handle invalid input
    if not grid_structure or not grid_structure.get('grids') or not isinstance(grid_structure.get('grids'), list):
        return [grid_structure]

    # Collect all children with their parent grid info
    all_children_with_grid_info = []
    for grid in grid_structure.get('grids', []):
        if grid.get('children') and isinstance(grid.get('children'), list):
            for child in grid['children']:
                all_children_with_grid_info.append({
                    'child': child,
                    'gridId': grid['id'],
                    'gridText': grid['gridText']
                })

    # If total children <= chunk size, return original structure
    if len(all_children_with_grid_info) <= chunk_size:
        return [grid_structure]

    # Split children into chunks
    chunks = []
    for i in range(0, len(all_children_with_grid_info), chunk_size):
        children_chunk = all_children_with_grid_info[i:i + chunk_size]

        # Group children by their parent grid
        grid_map = {}
        for item in children_chunk:
            if item['gridId'] not in grid_map:
                grid_map[item['gridId']] = {
                    'id': item['gridId'],
                    'gridText': item['gridText'],
                    'children': []
                }
            grid_map[item['gridId']]['children'].append(item['child'])

        # Convert map to array and create chunk with proper structure
        chunk_grids = list(grid_map.values())
        chunk = {
            'timestamp': grid_structure.get('timestamp'),
            'totalGrids': len(chunk_grids),
            'grids': chunk_grids
        }
        chunks.append(chunk)

    return chunks


def clean_grid_structure_for_llm(grid_structure):
    """
    Optimize grid structure for LLM by removing unnecessary data and limiting content
    """
    cleaned_structure = {
        'totalGrids': grid_structure.get('totalGrids', 0),
        'grids': []
    }

    if 'grids' in grid_structure:
        for grid in grid_structure['grids']:
            # Limit to essential data only
            cleaned_grid = {
                'id': grid.get('id'),
                'totalChildren': grid.get('totalChildren', 0),
                'children': []
            }
            
            # Add grid text if available (truncated for performance)
            if 'gridText' in grid:
                grid_text = grid['gridText']
                # Truncate grid text to prevent huge payloads
                if len(grid_text) > 500:
                    grid_text = grid_text[:500] + "..."
                cleaned_grid['gridText'] = grid_text

            # Process children with size limits - PRIORITIZE VISIBLE CONTENT
            if 'children' in grid:
                children = grid['children']
                # Limit to only the first 10 children (most visible) for faster processing
                max_children = 10  # Further reduced for speed
                if len(children) > max_children:
                    children = children[:max_children]
                
                for child in children:
                    cleaned_child = {
                        'id': child.get('id'),
                        'text': child.get('text', '')
                    }
                    # Truncate child text to prevent huge payloads
                    if len(cleaned_child['text']) > 50:  # Further reduced to 50 chars
                        cleaned_child['text'] = cleaned_child['text'][:50] + "..."
                    cleaned_grid['children'].append(cleaned_child)

            cleaned_structure['grids'].append(cleaned_grid)

    return cleaned_structure

def fallback_keyword_matching(cleaned_grid, blacklist):
    """
    Fallback keyword matching when AI returns empty response
    """
    if not blacklist or not cleaned_grid.get('grids'):
        return []
    
    result = []
    blacklist_lower = [keyword.lower() for keyword in blacklist]
    
    for grid in cleaned_grid.get('grids', []):
        for child in grid.get('children', []):
            child_text = child.get('text', '').lower()
            child_id = child.get('id')
            
            # Check if any blacklist keyword is in the child text
            for keyword in blacklist_lower:
                if keyword in child_text:
                    # Convert to the format expected by the frontend
                    grid_id = child_id.split('c')[0] if 'c' in child_id else grid.get('id', 'g1')
                    result.append({grid_id: [child_id]})
                    break  # Only add once per child
    
    return result

def convert_newline_format_to_json(newline_format):
    """
    Convert newline-separated child IDs back to original JSON format.

    Input: "g1c0\ng1c5\ng2c3"
    Output: [{"g1":["g1c0","g1c5"]},{"g2":["g2c3"]}]
    """
    if not newline_format or not newline_format.strip():
        return []

    # Parse child IDs and group by grid
    grid_map = {}
    child_ids = [child.strip() for child in newline_format.split('\n') if child.strip()]

    for child_id in child_ids:
        # Extract grid ID from child ID (e.g., "g1c0" -> "g1")
        if 'c' in child_id:
            grid_id = child_id.split('c')[0]
            if grid_id not in grid_map:
                grid_map[grid_id] = []
            grid_map[grid_id].append(child_id)

    # Convert to original JSON format
    result = []
    for grid_id, children in grid_map.items():
        result.append({grid_id: children})

    return result

def combine_chunk_results(chunk_results):
    """
    Combine results from multiple chunk API requests
    """
    # Check if any chunk failed
    for result in chunk_results:
        if not result.get('success'):
            return {
                'success': False,
                'error': result.get('error', 'One or more chunks failed')
            }

    # Combine all successful results
    combined_data = []
    for result in chunk_results:
        if result.get('data') and isinstance(result.get('data'), str):
            if result['data'].strip():  # Only add non-empty strings
                combined_data.append(result['data'].strip())

    # Join all chunks with newlines
    newline_format = '\n'.join(combined_data)

    # Convert back to original JSON format
    json_format = convert_newline_format_to_json(newline_format)

    return {
        'success': True,
        'data': json_format
    }

# API routes from server.js
# @app.get("/profile", response_class=FileResponse)
# async def profile(user: Dict = Depends(require_auth)):
#     """Serve the profile page."""
#     return FileResponse(Path(__file__).parent / "static" / "profile.html")

# @app.get("/api/profile-data")
# async def profile_data(user: Dict = Depends(require_auth)):
#     """Get profile data."""
#     try:
#         return {"user": user}
#     except Exception as e:
#         return JSONResponse(
#             status_code=500,
#             content={"error": f"Server error: {str(e)}"}
#         )

# @app.get("/api/user-info")
# async def user_info(user: Dict = Depends(require_auth)):
#     """Get user info."""
#     try:
#         return user
#     except Exception as e:
#         return JSONResponse(
#             status_code=500,
#             content={"error": f"Server error: {str(e)}"}
#         )

# @app.get("/api/config")
# async def get_config():
#     """Get Supabase configuration."""
#     try:
#         return {
#             "supabaseUrl": SUPABASE_URL,
#             "supabaseKey": SUPABASE_KEY,
#         }
#     except Exception as e:
#         return JSONResponse(
#             status_code=500,
#             content={"error": f"Server error: {str(e)}"}
#         )

# @app.get("/api/auth-status")
# async def auth_status(request: Request):
#     """Check authentication status."""
#     try:
#         user = get_user_from_session(request)
#         authenticated = is_authenticated(request)
#         return {
#             "isAuthenticated": authenticated,
#             "user": user if authenticated else None,
#         }
#     except Exception as e:
#         return JSONResponse(
#             status_code=500,
#             content={"error": f"Server error: {str(e)}"}
#         )

# @app.post("/api/logout")
# async def api_logout(request: Request, response: Response):
#     """Handle user logout."""
#     try:
#         # Clear session
#         was_authenticated = is_authenticated(request)
#         if was_authenticated:
#             request.session.pop("user", None)
#             response.delete_cookie("session")
#             # Clear auth cookies similar to Express.js implementation
#             response.delete_cookie("appSession")
#             response.delete_cookie("auth0.is.authenticated")

#         # Simple confirmation response
#         return {"success": True}
#     except Exception as e:
#         return JSONResponse(
#             status_code=500,
#             content={"error": f"Server error: {str(e)}"}
#         )

# @app.post("/api/check-username")
# async def check_username(data: Username):
#     """Check username availability."""
#     try:
#         username = data.username
#         if not username or username.strip() == "":
#             return JSONResponse(
#                 status_code=400,
#                 content={"error": "Username is required"}
#             )

#         clean_username = username.strip()

#         # Check if username exists in Supabase
#         try:
#             existing_score = supabase.table("game_scores").select("id").eq("username", clean_username).execute()

#             return {
#                 "success": True,
#                 "available": len(existing_score.data) == 0,
#                 "username": clean_username,
#             }
#         except Exception as supabase_error:
#             logger.error(f"Supabase error: {supabase_error}")
#             return JSONResponse(
#                 status_code=500,
#                 content={"error": f"Database error: {str(supabase_error)}"}
#             )
#     except Exception as e:
#         return JSONResponse(
#             status_code=500,
#             content={"error": f"Server error: {str(e)}"}
#         )

# @app.post("/api/save-score")
# async def save_score(data: ScoreData):
#     """Save user score."""
#     try:
#         username = data.username
#         score = data.score

#         if not username or username.strip() == "":
#             return JSONResponse(
#                 status_code=400,
#                 content={"error": "Username is required"}
#             )

#         if not isinstance(score, int):
#             return JSONResponse(
#                 status_code=400,
#                 content={"error": "Score must be a number"}
#             )

#         clean_username = username.strip()

#         # Check if user already exists and get their current high score
#         existing_scores = supabase.table("game_scores").select("score").eq("username", clean_username).execute()

#         if existing_scores.data:
#             # User exists, check if this is a new high score
#             current_high_score = max(score_record["score"] for score_record in existing_scores.data)
#             if score > current_high_score:
#                 # New high score - insert new record
#                 supabase.table("game_scores").insert({"username": clean_username, "score": score}).execute()
#                 return {
#                     "success": True,
#                     "username": clean_username,
#                     "score": score,
#                     "message": "New high score saved!",
#                     "highScore": score,
#                 }
#             else:
#                 # Not a high score, but still save the attempt
#                 supabase.table("game_scores").insert({"username": clean_username, "score": score}).execute()
#                 return {
#                     "success": True,
#                     "username": clean_username,
#                     "score": score,
#                     "message": "Score saved!",
#                     "highScore": current_high_score,
#                 }
#         else:
#             # New user - save score
#             supabase.table("game_scores").insert({"username": clean_username, "score": score}).execute()
#             return {
#                 "success": True,
#                 "username": clean_username,
#                 "score": score,
#                 "message": "New high score saved!",
#                 "highScore": score,
#             }
#     except Exception as e:
#         return JSONResponse(
#             status_code=500,
#             content={"error": f"Server error: {str(e)}"}
#         )

# @app.get("/api/leaderboard")
# async def leaderboard():
#     """Get leaderboard data."""
#     try:
#         # Get all scores from Supabase, grouped by username with max score
#         scores = supabase.table("game_scores").select("username, score").execute()

#         if not scores.data:
#             return {
#                 "success": True,
#                 "leaderboard": [],
#             }

#         # Group by username and get highest score for each user
#         user_scores = {}
#         for score_record in scores.data:
#             username = score_record["username"]
#             score = score_record["score"]
#             if username not in user_scores or score > user_scores[username]:
#                 user_scores[username] = score

#         # Convert to list format and sort by score descending
#         leaderboard = [{"username": username, "score": score} for username, score in user_scores.items()]
#         leaderboard.sort(key=lambda x: x["score"], reverse=True)

#         return {
#             "success": True,
#             "leaderboard": leaderboard,
#         }
#     except Exception as e:
#         return JSONResponse(
#             status_code=500,
#             content={"error": f"Server error: {str(e)}"}
#         )

# @app.get("/game")
# async def game():
#     return RedirectResponse(url="/#game-banner")

# @app.get("/")
# async def root():
#     """Serve the landing page."""
#     return FileResponse(Path(__file__).parent / "static" / "index.html")

# Serve individual CSS and JS files
# @app.get("/styles.css")
# async def get_styles():
#     return FileResponse(Path(__file__).parent / "static" / "styles.css")

# @app.get("/script.js")
# async def get_script():
#     return FileResponse(Path(__file__).parent / "static" / "script.js")

# Mount static files - put at the end to avoid conflicts with API routes
# app.mount("/assets", StaticFiles(directory="static/assets"), name="assets")
# app.mount("/static", StaticFiles(directory="static"), name="static")

logger.info("Prompts loaded successfully")

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    logger.info("Starting server on localhost:%s" % port)
    uvicorn.run(app, host="localhost", port=port)
